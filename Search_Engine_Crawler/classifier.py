from random import sample
import pandas as pd
import logging
import ast
import sklearn
import re
import emoji
import unicodedata
from sklearn import tree, metrics
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.svm import LinearSVC
from util import *

def Predict_With_Model(model, terms):

    def numeric_num(term):
        cnt = 0
        for s in term:
            if s.isdecimal():
                cnt += 1
        return cnt

    def patterns_num(term):
        patterns = ['å¾®ä¿¡', 'qå¾®', 'æ‰£å¾®', 'å¾®', 'è–‡', 'æ‰£æ‰£', 'qq',\
                    'com', 'fun', 'cc', 'hash', 'tg', 'telegram', \
                    'é£æœº', '@', 'ç½‘', 'å¤åˆ¶', 'vä¿¡','ì»´', 'www']
        cnt = 0
        for p in patterns:
            if p in term.lower():
                cnt += 1
        return cnt

    def brackets_num(term):
        brackets_list = ['ã€ˆ', 'ã€‰', 'ã€Š', 'ã€‹', 'ã€Œ', 'ã€', 'ã€', 'ã€', 'ã€', 'ã€‘', 'ã€”', 'ã€•',\
                        'ï¹™', 'ï¹š', 'ï¹›', 'ï¹œ', 'ï¹', 'ï¹', 'ï¹¤', 'ï¹¥', 'ï¼ˆ', 'ï¼‰', 'ï¼œ', 'ï¼',\
                        'ï½›', 'ï½', 'â¬', 'â­', 'â®', 'â¯', 'â°', 'â±', 'ã€–', 'ã€—', 'ã€˜', 'ã€™', 'ã€š', 'ã€›',\
                        'âŒ©', 'âŒª', 'â€¹', 'â€º', 'Â«', 'Â»', 'ï½¢', 'ï½£', '(', ')', '[', ']']
        cnt = 0
        for p in brackets_list:
            if p in term:
                cnt += 1
        return cnt

    def has_suffix(term):
        suffix = ['.html', '.shtml', '.htm', '.php', '.pdf', '.jpg', '.jpeg', '.png', '.xlsx', '.doxx', '.pptx', '.xml']
        for s in suffix:
            if s in term:
                return 1
        return 0

    def url_num(term):
        url_pattern = r'[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+\.?'
        return len(re.findall(url_pattern, term))
    
    def emoji_num(term):
        return emoji.emoji_count(term)
        
    def unicodesymbol_num(term):
        cnt = 0
        for char in term:
            if unicodedata.category(char).startswith('S'):
                cnt += 1
        return cnt

    def feature_extract(sample):
        features = []
        # length in in characters
        features.append(len(sample))
        # number of brackets
        features.append(brackets_num(sample))
        # number of urls in term
        features.append(url_num(sample))
        # number of emojis
        features.append(emoji_num(sample))
        # number of unicode symbols
        features.append(unicodesymbol_num(sample))
        # number of numberic characters
        features.append(numeric_num(sample))
        # num of some contact info patterns
        features.append(patterns_num(sample))
        # if some suffix of web file in sample
        features.append(has_suffix(sample))
        return features
    features = [
        feature_extract(sample)
        for sample in terms
    ]
    return model.predict(features)


def Predict_Keywords_With_Model(model, keywords):
    def non_alphanumeric_num(term):
        cnt = 0
        for s in term:
            if (not s.isalpha()) and (not s.isdecimal()):
                cnt += 1
        return cnt

    def numeric_num(term):
        cnt = 0
        for s in term:
            if s.isdecimal():
                cnt += 1
        return cnt

    def patterns_num(term):
        patterns = ['å¾®ä¿¡', 'qå¾®', 'æ‰£å¾®', 'å¾®', 'è–‡', 'æ‰£æ‰£', 'qq',\
                    'com', 'fun', 'cc', 'hash', 'tg', 'telegram', \
                    'é£æœº', '@']
        cnt = 0
        for p in patterns:
            if p in term.lower():
                cnt += 1
        return cnt

    def brackets_num(term):
        brackets_num = ['[', ']', 'ã€', 'ã€‘', '(', ')', 'ï¼ˆ',\
                    'ï¼‰', 'ã€', 'ã€', 'ã€Š', 'ã€‹', '<', \
                    '>', 'â˜€ï¸', 'ğŸ‘‰']
        cnt = 0
        for p in brackets_num:
            if p in term:
                cnt += 1
        return cnt

    def has_suffix(term):
        suffix = ['.html', '.shtml', '.htm', '.php', '.pdf', '.jpg', '.jpeg', '.png', '.xlsx', '.doxx', '.pptx', '.xml']
        for s in suffix:
            if s in term:
                return 1
        return 0

    def url_num(term):
        url_pattern = r'[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+\.?'
        return len(re.findall(url_pattern, term))

    def punctuation_num(term):
        patterns =  ['.', ':', 'ï¼š', 'Â·', 'Íº', '-']
        cnt = 0
        for p in patterns:
            if p in term.lower():
                cnt += 1
        return cnt
    
    def alphanumeric_num(term):
        cnt = 0
        for s in term:
            if s.isalpha() or s.isdecimal():
                cnt += 1
        return cnt

    def feature_extract(sample):
        features = []
        # length in characters
        features.append(len(sample))
        # number of urls in term
        features.append(url_num(sample))
        # number of non alphanumeric characters
        features.append(non_alphanumeric_num(sample))
        # number of alphanumeric characters
        features.append(alphanumeric_num(sample))
        # number of numberic characters
        features.append(numeric_num(sample))
        # num of some contact info patterns
        features.append(patterns_num(sample))
        # Number of some common punctuation marks
        features.append(punctuation_num(sample))
        # if some suffix of web file in sample
        features.append(has_suffix(sample))
        #TODO more features
        return features

    features = [
        feature_extract(sample)
        for sample in keywords
    ]
    return model.predict(features)